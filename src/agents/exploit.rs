use std::sync::Arc;
use crate::errors::SekuraError;
use crate::llm::provider::LLMProvider;
use crate::models::finding::{Finding, Severity, VulnCategory, FindingSource};
use crate::models::verdict::Verdict;
use crate::pipeline::state::PipelineConfig;
use crate::prompts::{PromptLoader, PromptVariables};
use crate::queue::{ExploitationQueue, VulnType};
use tracing::{info, warn, debug};

/// Runs the LLM-based exploitation phase for a single vuln category.
/// Takes the exploitation queue produced by the vuln agent and attempts to exploit each entry.
/// Returns findings with verdicts, proof-of-exploit evidence, and LLM cost in USD.
pub async fn run_exploitation(
    vuln_type: VulnType,
    queue: &ExploitationQueue,
    llm: Arc<dyn LLMProvider>,
    prompt_loader: Arc<PromptLoader>,
    config: &PipelineConfig,
) -> Result<(Vec<Finding>, Option<f64>), SekuraError> {
    if queue.vulnerabilities.is_empty() {
        info!(vuln_type = %vuln_type.as_str(), "No vulnerabilities to exploit");
        write_empty_evidence(vuln_type, config).await?;
        return Ok((Vec::new(), None));
    }

    let deliverables_dir = config.deliverables_dir();
    let prompt_name = format!("exploit-{}", vuln_type.as_str());

    // Load and interpolate the exploit prompt template
    let system = match prompt_loader.load(&prompt_name) {
        Ok(template) => {
            let vars = build_exploit_variables(vuln_type, config, &deliverables_dir).await;
            prompt_loader.interpolate(&template, &vars)
        }
        Err(e) => {
            warn!(vuln_type = %vuln_type.as_str(), error = %e, "Failed to load exploit prompt, using fallback");
            format!(
                "You are a {} exploitation specialist. Exploit the vulnerabilities in the queue against the target.",
                vuln_type.as_str()
            )
        }
    };

    // Serialize the queue for the prompt
    let queue_json = serde_json::to_string_pretty(queue)
        .map_err(|e| SekuraError::Internal(format!("Failed to serialize queue: {}", e)))?;

    // Build user prompt with queue and context
    let mut prompt = format!(
        "Exploit the following {} vulnerabilities against target {}.\n\n\
         ## Exploitation Queue\n```json\n{}\n```\n\n",
        vuln_type.as_str(), config.target, queue_json
    );

    // Feed tool findings for additional context
    if let Some(content) = read_deliverable(&deliverables_dir, "tool_findings_report.md", 5000).await {
        prompt.push_str("## Tool Findings Context\n");
        prompt.push_str(&content);
        prompt.push_str("\n\n");
    }

    // Feed recon data
    if let Some(content) = read_deliverable(&deliverables_dir, "recon_deliverable.md", 5000).await {
        prompt.push_str("## Recon Context\n");
        prompt.push_str(&content);
        prompt.push_str("\n\n");
    }

    prompt.push_str(
        "For each vulnerability in the queue:\n\
         1. Attempt exploitation via the external interface\n\
         2. Document the exact steps, payloads used, and responses observed\n\
         3. Assign a verdict: EXPLOITED, BLOCKED_BY_SECURITY, FALSE_POSITIVE, POTENTIAL, or OUT_OF_SCOPE_INTERNAL\n\
         4. Provide proof of exploit (HTTP request/response, extracted data, screenshot description)\n\n\
         Format your response as a markdown report with a section per vulnerability.\n\
         Include a JSON summary block:\n\
         ```json\n\
         {\"results\": [{\"id\": \"...\", \"verdict\": \"...\", \"severity\": \"critical|high|medium|low|info\", \
         \"proof\": \"...\", \"impact\": \"...\"}]}\n\
         ```\n"
    );

    info!(vuln_type = %vuln_type.as_str(), queue_size = queue.vulnerabilities.len(), "Running LLM exploitation");
    let response = llm.complete(&prompt, Some(&system)).await?;
    let cost_usd = response.cost_usd;

    // Write exploitation evidence deliverable
    let evidence_filename = vuln_type.evidence_filename();
    tokio::fs::write(deliverables_dir.join(&evidence_filename), &response.content).await?;
    info!(file = %evidence_filename, "Wrote exploitation evidence");

    // Parse exploitation results from LLM response
    let findings = parse_exploit_results(&response.content, vuln_type, queue);

    Ok((findings, cost_usd))
}

/// Parse exploit results from the LLM response into findings with verdicts.
fn parse_exploit_results(
    response: &str,
    vuln_type: VulnType,
    queue: &ExploitationQueue,
) -> Vec<Finding> {
    let category = match vuln_type {
        VulnType::Injection => VulnCategory::Injection,
        VulnType::Xss => VulnCategory::Xss,
        VulnType::Auth => VulnCategory::Auth,
        VulnType::Ssrf => VulnCategory::Ssrf,
        VulnType::Authz => VulnCategory::Authz,
    };

    // Try to parse the JSON results block
    if let Some(results) = extract_results_json(response) {
        return results.iter().filter_map(|result| {
            let id = result.get("id").and_then(|v| v.as_str()).unwrap_or("");
            let verdict_str = result.get("verdict").and_then(|v| v.as_str()).unwrap_or("POTENTIAL");
            let proof = result.get("proof").and_then(|v| v.as_str()).unwrap_or("");
            let impact = result.get("impact").and_then(|v| v.as_str()).unwrap_or("");
            let severity_str = result.get("severity").and_then(|v| v.as_str()).unwrap_or("medium");

            let verdict = parse_verdict(verdict_str);
            if !verdict.is_reportable() {
                return None;
            }

            let severity = match severity_str {
                "critical" => Severity::Critical,
                "high" => Severity::High,
                "medium" => Severity::Medium,
                "low" => Severity::Low,
                _ => Severity::Info,
            };

            // Find the original queue entry for context
            let queue_entry = queue.vulnerabilities.iter().find(|e| e.id == id);
            let title = queue_entry
                .map(|e| format!("{}: {} at {}", vuln_type.as_str().to_uppercase(), e.vulnerability_type, e.path.as_deref().unwrap_or("N/A")))
                .unwrap_or_else(|| format!("{}: Exploited vulnerability {}", vuln_type.as_str().to_uppercase(), id));

            Some(Finding {
                title,
                severity,
                category: category.clone(),
                description: impact.to_string(),
                evidence: proof.to_string(),
                recommendation: "Remediate immediately â€” exploitation was confirmed.".to_string(),
                tool: "llm-exploit".to_string(),
                technique: format!("exploit-{}", vuln_type.as_str()),
                source: FindingSource::Combined,
                verdict: Some(verdict),
                proof_of_exploit: Some(proof.to_string()),
                cwe_id: None,
                cvss_score: None,
                cvss_vector: None,
            })
        }).collect();
    }

    // Fallback: create findings from queue entries based on response keyword analysis
    queue.vulnerabilities.iter().filter_map(|entry| {
        let verdict = if response.to_lowercase().contains("exploited") && response.contains(&entry.id) {
            Verdict::Exploited
        } else if response.to_lowercase().contains("blocked") && response.contains(&entry.id) {
            Verdict::BlockedBySecurity
        } else {
            Verdict::Potential
        };

        if !verdict.is_reportable() {
            return None;
        }

        Some(Finding {
            title: format!("{}: {} at {}", vuln_type.as_str().to_uppercase(), entry.vulnerability_type, entry.path.as_deref().unwrap_or("N/A")),
            severity: Severity::Medium,
            category: category.clone(),
            description: entry.exploitation_hypothesis.clone().unwrap_or_else(|| entry.vulnerability_type.clone()),
            evidence: response[..response.len().min(2000)].to_string(),
            recommendation: "Validate and remediate".to_string(),
            tool: "llm-exploit".to_string(),
            technique: format!("exploit-{}", vuln_type.as_str()),
            source: FindingSource::Combined,
            verdict: Some(verdict),
            proof_of_exploit: Some(response[..response.len().min(2000)].to_string()),
            cwe_id: None,
            cvss_score: None,
            cvss_vector: None,
        })
    }).collect()
}

fn parse_verdict(s: &str) -> Verdict {
    match s.to_uppercase().as_str() {
        "EXPLOITED" => Verdict::Exploited,
        "BLOCKED_BY_SECURITY" => Verdict::BlockedBySecurity,
        "OUT_OF_SCOPE_INTERNAL" => Verdict::OutOfScopeInternal,
        "FALSE_POSITIVE" => Verdict::FalsePositive,
        _ => Verdict::Potential,
    }
}

fn extract_results_json(text: &str) -> Option<Vec<serde_json::Value>> {
    // Look for ```json ... ``` blocks containing "results"
    let markers = ["```json\n", "```json\r\n"];
    for marker in markers {
        if let Some(start) = text.find(marker) {
            let json_start = start + marker.len();
            if let Some(end) = text[json_start..].find("```") {
                let json_str = &text[json_start..json_start + end].trim();
                if let Ok(val) = serde_json::from_str::<serde_json::Value>(json_str) {
                    if let Some(results) = val.get("results").and_then(|v| v.as_array()) {
                        return Some(results.clone());
                    }
                }
            }
        }
    }

    // Try raw JSON with "results" key
    if let Some(start) = text.find("{\"results\"") {
        let mut depth = 0;
        for (i, ch) in text[start..].char_indices() {
            match ch {
                '{' => depth += 1,
                '}' => {
                    depth -= 1;
                    if depth == 0 {
                        let json_str = &text[start..start + i + 1];
                        if let Ok(val) = serde_json::from_str::<serde_json::Value>(json_str) {
                            if let Some(results) = val.get("results").and_then(|v| v.as_array()) {
                                return Some(results.clone());
                            }
                        }
                        break;
                    }
                }
                _ => {}
            }
        }
    }

    None
}

/// Write empty evidence file when there are no vulnerabilities to exploit.
async fn write_empty_evidence(vuln_type: VulnType, config: &PipelineConfig) -> Result<(), SekuraError> {
    let deliverables_dir = config.deliverables_dir();
    let evidence_filename = vuln_type.evidence_filename();
    let path = deliverables_dir.join(&evidence_filename);
    if !path.exists() {
        tokio::fs::write(
            &path,
            format!("# {} Exploitation Evidence\n\nNo exploitable vulnerabilities found.\n", vuln_type.as_str().to_uppercase()),
        ).await?;
    }
    Ok(())
}

/// Build prompt variables for exploit prompts.
async fn build_exploit_variables(
    vuln_type: VulnType,
    config: &PipelineConfig,
    deliverables_dir: &std::path::Path,
) -> PromptVariables {
    let code_analysis = read_deliverable(deliverables_dir, "code_analysis_deliverable.md", 5000).await;
    let recon_data = read_deliverable(deliverables_dir, "recon_deliverable.md", 5000).await;
    let tool_findings = read_deliverable(deliverables_dir, "tool_findings_report.md", 5000).await;
    let queue_filename = vuln_type.queue_filename();
    let exploitation_queue = read_deliverable(deliverables_dir, &queue_filename, 10000).await;

    PromptVariables {
        target_url: config.target.clone(),
        repo_path: if config.has_repo() {
            Some(config.repo_path.display().to_string())
        } else {
            None
        },
        intensity: format!("{:?}", config.intensity),
        code_analysis,
        recon_data,
        tool_findings,
        exploitation_queue,
        vuln_type: Some(vuln_type.as_str().to_string()),
        rules_avoid: config.rules_avoid.clone(),
        rules_focus: config.rules_focus.clone(),
        login_instructions: None,
        open_ports: None,
        cookie_string: config.cookie.clone(),
        auth_context: config.auth_context.clone(),
    }
}

async fn read_deliverable(dir: &std::path::Path, filename: &str, max_len: usize) -> Option<String> {
    let path = dir.join(filename);
    match tokio::fs::read_to_string(&path).await {
        Ok(content) if !content.trim().is_empty() => {
            Some(content[..content.len().min(max_len)].to_string())
        }
        _ => None,
    }
}
